import threading
import time
import queue
import os
import asyncio
import json # å¼•å…¥ json åº“
import datetime
from tracemalloc import start
import torch

from fastapi import FastAPI, HTTPException,Request
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from api.data_processing import process_data # å‡è®¾ä½ çš„å¤„ç†å‡½æ•°åœ¨è¿™é‡Œ
from api.LSTM import init_model
from api.car_queue import CarQueue,StrideNode
from api.NLT_main import likelihood_transformation

# 1. åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="è½¦è”ç½‘å…¥ä¾µæ£€æµ‹ç³»ç»Ÿåç«¯",
    description="ä¸€ä¸ªä½¿ç”¨FastAPIå’Œå¤šçº¿ç¨‹çš„æµå¼æ•°æ®å¤„ç†æœåŠ¡",
    version="1.0.0",
)

# 2. é…ç½®CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 3. å…¨å±€å˜é‡
# æ ‡å‡†é˜Ÿåˆ—ï¼Œç”¨äºåŒæ­¥çš„çº¿ç¨‹é—´é€šä¿¡ (API -> Worker)
data_in_queue = queue.Queue()
# å¼‚æ­¥é˜Ÿåˆ—ï¼Œç”¨äº Worker -> API çš„é€šä¿¡
results_out_queue = asyncio.Queue()
# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨å¯åŠ¨æ—¶åŠ è½½çš„æ•°æ®
loaded_data = {}
# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨ä¸»çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯ï¼Œä»¥ä¾¿å·¥ä½œçº¿ç¨‹å¯ä»¥å®‰å…¨åœ°è°ƒç”¨å¼‚æ­¥ä»£ç 
main_loop = None
# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹å’Œè®¾å¤‡
model=None
device=None
stride_time = 1
size = int(30 / stride_time)
car_queue=CarQueue(max_len=size, stride=stride_time)


# --- å·¥ä½œçº¿ç¨‹å®šä¹‰ ---
def worker_thread_task():
    """
    å·¥ä½œçº¿ç¨‹ï¼šè·å–åŸå§‹æ•°æ®ï¼Œè¿›è¡Œå¤„ç†ï¼Œå¹¶å°†ç»“æœæ”¾å…¥è¾“å‡ºé˜Ÿåˆ—ã€‚
    
    """
    model,device = init_model()
    print(f"ğŸ‘ é²æ£’çš„LSTMæ¨¡å‹åŠ è½½å®Œæˆ")
    # print("âœ… å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨ï¼Œç­‰å¾…æ•°æ®...")
    loss=0
    label_predict=0
    result=None
    label=None
    criterion=torch.nn.MSELoss()
    transfer=likelihood_transformation()
    transfer.set_global_max(0.1086178408236927)
    stride_node = StrideNode(stride_time)
    start_time = 0
    while True:
        # ä»è¾“å…¥é˜Ÿåˆ—è·å–åŸå§‹æ•°æ®é¡¹
        # data_type ç”¨äºäº†è§£ä¸Šä¸‹æ–‡, item æ˜¯å…·ä½“çš„æ•°æ®è¡Œ
        data_type, new_data = data_in_queue.get()
        if start_time + stride_time > new_data[0]:
            # print(start_time,new_data[0])
            stride_node.add_data(new_data)
        else:
            car_queue.append(stride_node)
            if len(car_queue) == size:
                result, label = car_queue.get_result()
                stride_node = StrideNode(stride_time)
                stride_node.add_data(new_data)
                z=transfer.out(result) 
                z=torch.from_numpy(z).float()
                if z.dim() == 1:
                    z = z.view(1, -1, 1) 
                z=z.to(device)
                z_hat=model(z)
                loss=criterion(z_hat,z)
                print(loss)
                label_predict=1
                if loss>0.0007360850974392888:
                    label_predict=0
                        # å‡†å¤‡è¦è¿”å›ç»™å‰ç«¯çš„å¤„ç†ç»“æœ
                result_data = {
                    "time": time.time(),
                    "loss": loss,
                    "original_label": data_type,
                    "predicted_label":label_predict
                }
                
                # â€¼ï¸ å…³é”®: ä»åŒæ­¥çš„ worker çº¿ç¨‹ä¸­ï¼Œå®‰å…¨åœ°å°†ç»“æœæ”¾å…¥å¼‚æ­¥çš„ results_out_queue
                # æˆ‘ä»¬å¿…é¡»ä½¿ç”¨ run_coroutine_threadsafeï¼Œå› ä¸ºå®ƒèƒ½ç¡®ä¿çº¿ç¨‹å®‰å…¨
                if main_loop and not main_loop.is_closed():
                    asyncio.run_coroutine_threadsafe(results_out_queue.put(result_data), main_loop)


            start_time += stride_time
            while start_time + stride_time < new_data[0]:
                stride_node = StrideNode(stride_time)
                car_queue.append(stride_node)
                start_time += stride_time
            
        if new_data is None:
            print("å·¥ä½œçº¿ç¨‹æ”¶åˆ°ç»“æŸä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
            # å‘ç»“æœé˜Ÿåˆ—ä¹Ÿæ”¾å…¥ä¸€ä¸ªç»ˆæ­¢ä¿¡å·ï¼Œä»¥é˜²æœ‰ç›‘å¬å™¨åœ¨ç­‰å¾…
            if main_loop and not main_loop.is_closed():
                asyncio.run_coroutine_threadsafe(results_out_queue.put(None), main_loop)
            break

    print("ğŸ›‘ å·¥ä½œçº¿ç¨‹å·²åœæ­¢ã€‚")


# --- FastAPI ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ï¼šåº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œ ---
@app.on_event("startup")
async def startup_event():
    """
    åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œçš„åˆå§‹åŒ–å‡½æ•°ã€‚
    """
    global main_loop
    print("--- â€¼ï¸ ç³»ç»Ÿåˆå§‹åŒ–é˜¶æ®µå¼€å§‹ â€¼ï¸ ---")
    main_loop = asyncio.get_running_loop()
    
    # ä»»åŠ¡1: åŠ è½½æ‰€æœ‰æ•°æ®é›†
    print("â¡ï¸ æ­¥éª¤ 1/2: æ­£åœ¨åŠ è½½å’Œå¤„ç†æ•°æ®é›†...")
    # å®šä¹‰æ•°æ®é›†è·¯å¾„
    datasets = {
        "æ­£å¸¸æµé‡": './data/normal_run_data.txt',
        # "Dosæ”»å‡»": './data/DoS_dataset.csv',
        # "æ¨¡ç³Šæ”»å‡»": './data/Fuzzy_dataset.csv',
        # "Gearæ”»å‡»": './data/Gear_dataset.csv',
        # "RPMæ”»å‡»": './data/RPM_dataset.csv'
    }
    
    # å¾ªç¯åŠ è½½æ‰€æœ‰æ•°æ®
    for name, path in datasets.items():
        if os.path.exists(path):
            # ä½¿ç”¨ä½ çš„ process_data å‡½æ•°åŠ è½½æ•°æ®
            loaded_data[name] = process_data(path)
            print(f"  âœ… {name} - åŠ è½½æˆåŠŸ")
        else:
            print(f"  âŒ {name} - æ–‡ä»¶æœªæ‰¾åˆ°: {path}")

    print(f"ğŸ‘ æ•°æ®é›†åŠ è½½å®Œæˆã€‚å·²åŠ è½½çš„ç±»å‹: {list(loaded_data.keys())}")

    # å¯åŠ¨å·¥ä½œçº¿ç¨‹
    print("â¡ï¸ æ­¥éª¤ 2/2: æ­£åœ¨å¯åŠ¨åå°å·¥ä½œçº¿ç¨‹...")
    worker = threading.Thread(target=worker_thread_task, daemon=True)
    worker.start()
    print("ğŸ‘ åå°å·¥ä½œçº¿ç¨‹å·²æˆåŠŸå¯åŠ¨ã€‚")
    print("--- âœ… ç³»ç»Ÿåˆå§‹åŒ–é˜¶æ®µå®Œæˆ ---")

@app.on_event("shutdown")
async def shutdown_event():
    # å‘è¾“å…¥é˜Ÿåˆ—å‘é€ç»ˆæ­¢ä¿¡å·
    data_in_queue.put((None, None))
    print("\n--- ç³»ç»Ÿæ­£åœ¨å…³é—­ï¼Œå·²å‘å·¥ä½œçº¿ç¨‹å‘é€åœæ­¢ä¿¡å· ---")


# --- API ç«¯ç‚¹å®šä¹‰ ---

# âœ… ä¿®æ­£åçš„ /read_dataset ç«¯ç‚¹
@app.get("/read_dataset")
async def stream_dataset(data_type: str):
    """
    æ ¹æ®æ•°æ®ç±»å‹ï¼Œæµå¼è¿”å›å¯¹åº”çš„æ•°æ®é›†å†…å®¹ã€‚
    è¾“å‡ºçš„æ¯ä¸€è¡Œéƒ½åŒ…å«äº† ANSI é¢œè‰²ä»£ç ï¼Œä»¥ä¾›å‰ç«¯è§£æã€‚
    """
    if data_type not in loaded_data:
        raise HTTPException(status_code=404, detail=f"è¯·æ±‚çš„æ•°æ®ç±»å‹ '{data_type}' æœªåœ¨åç«¯åŠ è½½")

    # å®šä¹‰ANSIé¢œè‰²ä»£ç ï¼Œç”¨äºåœ¨æ–‡æœ¬æµä¸­åµŒå…¥é¢œè‰²ä¿¡æ¯
    COLOR_RED = "\u001b[31m"    # çº¢è‰²ï¼Œé€šå¸¸ç”¨äºè¡¨ç¤ºå¼‚å¸¸/æ”»å‡»
    COLOR_GREEN = "\u001b[32m"  # ç»¿è‰²ï¼Œé€šå¸¸ç”¨äºè¡¨ç¤ºæ­£å¸¸
    COLOR_RESET = "\u001b[0m"   # é‡ç½®ä»£ç ï¼Œæ¢å¤é»˜è®¤é¢œè‰²

    async def data_generator():
        data_to_stream = loaded_data[data_type]
        print(f"\nâ–¶ï¸ å¼€å§‹æ¨é€ '{data_type}' æ•°æ®æµ (å¸¦é¢œè‰²)...")
        
        previous_item = None # ç”¨äºè®¡ç®—ä¸ä¸Šä¸€ä¸ªæ•°æ®ç‚¹çš„æ—¶é—´å·®
        time_start = time.time()
        for item in data_to_stream:
            # --- 1. è®¡ç®—ä¸ä¸Šä¸€ä¸ªæ•°æ®ç‚¹çš„æ—¶é—´å·®ï¼Œä»¥æ¨¡æ‹ŸçœŸå®çš„æ—¶é—´æµ ---
            sleep_duration = 0.05  # å¦‚æœæ˜¯ç¬¬ä¸€è¡Œæˆ–æ—¶é—´æˆ³æ— æ•ˆï¼Œåˆ™ä½¿ç”¨ä¸€ä¸ªå›ºå®šçš„çŸ­é—´éš”
            
            if previous_item is not None:
                try:
                    # ç¡®ä¿æ—¶é—´æˆ³æ˜¯æµ®ç‚¹æ•°ç±»å‹ä»¥ä¾¿è®¡ç®—
                    current_timestamp = float(item[0])
                    previous_timestamp = float(previous_item[0])
                    delta = current_timestamp - previous_timestamp
                    time_end =time.time()
                    # ç¡®ä¿ç­‰å¾…æ—¶é—´éè´Ÿ
                    if time_end - time_start>0:
                        delta-=(time_end-time_start)
                    sleep_duration = max(0, delta)
                    time_start = time.time()

                except (ValueError, TypeError, IndexError):
                    print(f"è­¦å‘Šï¼šæ— æ³•è§£ææ—¶é—´æˆ³æˆ–æ•°æ®é¡¹æ ¼å¼é”™è¯¯: {item}")
                    pass # ä½¿ç”¨é»˜è®¤é—´éš”
            
            await asyncio.sleep(sleep_duration)
            
            # --- 2. å‡†å¤‡è¦å‘é€ç»™å‰ç«¯çš„å•è¡Œæ•°æ® ---
            
            # ç¡®å®šæ ‡ç­¾å’Œå¯¹åº”çš„é¢œè‰² (å‡è®¾ '1' æˆ– 'R' ä»£è¡¨æ­£å¸¸, å…¶ä»–ä¸ºå¼‚å¸¸)
            # æ³¨æ„ï¼šitem[-1] çš„å€¼åº”è¯¥æ˜¯å­—ç¬¦ä¸² '0' æˆ– '1'
            label = item[-1].strip() 
            if label == 'R': 
                label = '1' # å°† 'R' ç»Ÿä¸€ä¸º '1'
            else: 
                label = '0'

            color_code = COLOR_GREEN if label == '1' else COLOR_RED
    
            # æ„å»ºå°†å‘é€ç»™å‰ç«¯çš„åŸå§‹æ–‡æœ¬è¡Œ
            # æ ¼å¼: æ—¶é—´æˆ³ ID:xxx DLC:x Data:xx xx xx xx æ ‡ç­¾
            # raw_line = f"{time.time()} ID:{item[1]} DLC:{int(item[2])} {item[3]},{item[-1]}"
            raw_line = f"{item[0]} ID:{item[1]} DLC:{int(item[2])} {item[3]},{item[-1]}"

            # --- 3. ç»„åˆæœ€ç»ˆçš„æµå¼å­—ç¬¦ä¸² ---
            # æ ¼å¼: [é¢œè‰²ä»£ç ]åŸå§‹æ–‡æœ¬[é‡ç½®é¢œè‰²ä»£ç ][æ¢è¡Œç¬¦]
            data_str = f"{color_code}{raw_line}{COLOR_RESET}\n"
            data_in_queue.put((data_type, item))
            yield data_str.encode("utf-8")
            
            # æ›´æ–° previous_item ä»¥ä¾›ä¸‹ä¸€æ¬¡å¾ªç¯è®¡ç®—æ—¶é—´å·®
            previous_item = item

        print(f"â¹ï¸ '{data_type}' æ•°æ®æµæ¨é€å®Œæ¯•ã€‚")

    # è¿”å›ä¸€ä¸ªæµå¼å“åº”ï¼ŒFastAPI ä¼šè‡ªåŠ¨å¤„ç†è¿™ä¸ªç”Ÿæˆå™¨
    return StreamingResponse(data_generator(), media_type="text/event-stream")


# âœ… æ–°å¢çš„ /detect_attack ç«¯ç‚¹ (æµå¼)
@app.get("/detect_attack")
async def stream_detections(request: Request):
    """
    èŒè´£:
    1. ä½œä¸ºä¸€ä¸ªé•¿è¿æ¥ï¼ŒæŒç»­ç­‰å¾… `results_out_queue` ä¸­çš„æ–°æ•°æ®ã€‚
    2. å°†ä»å·¥ä½œçº¿ç¨‹æ”¶åˆ°çš„å¤„ç†ç»“æœï¼Œæµå¼æ¨é€åˆ°å‰ç«¯ã€‚
    """
    async def detection_generator():
        print(f"\nâ–¶ï¸ å‰ç«¯å·²è¿æ¥ï¼Œå¼€å§‹ç›‘å¬å¤„ç†ç»“æœ...")
        try:
            while True:
                # å¼‚æ­¥åœ°ä»ç»“æœé˜Ÿåˆ—ä¸­è·å–ä¸€ä¸ªé¡¹ç›®
                # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œå®ƒä¼šåœ¨è¿™é‡Œç­‰å¾…ï¼Œè€Œä¸ä¼šé˜»å¡æœåŠ¡å™¨
                result = await results_out_queue.get()

                if result is None: # å¦‚æœæ”¶åˆ°ç»ˆæ­¢ä¿¡å·
                    break

                # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦å·²æ–­å¼€è¿æ¥
                if await request.is_disconnected():
                    print("âŒ å®¢æˆ·ç«¯å·²æ–­å¼€è¿æ¥ï¼Œåœæ­¢æ¨é€æ£€æµ‹ç»“æœã€‚")
                    break
                
                current_time=result['time']
                loss=result['loss']
                label=result['original_label']
                label_predict=result['predicted_label']
                # å°†ç»“æœæ ¼å¼åŒ–ä¸º JSON å­—ç¬¦ä¸²å¹¶æ¨é€
                # åç«¯è¿”å›æ ¼å¼ä¸º f"{current_time,float(loss),label,label_predict}\n"
                data_line = f"{current_time},{loss},{label},{label_predict}\n"
            
                # å°†æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²å‘é€ç»™å‰ç«¯
                yield data_line.encode("utf-8")
        finally:
            print("â¹ï¸ æ£€æµ‹ç»“æœç›‘å¬ç»“æŸã€‚")

    return StreamingResponse(detection_generator(), media_type="application/x-ndjson")